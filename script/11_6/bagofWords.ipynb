{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bagofWords.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PUNwunP-AXT5","colab_type":"text"},"source":["## Bag-of-Words Classifier"]},{"cell_type":"code","metadata":{"id":"X6N61OQiAevw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"de595c54-9453-4058-e3b4-a5c05b55922d","executionInfo":{"status":"ok","timestamp":1572763677636,"user_tz":-480,"elapsed":5867,"user":{"displayName":"陈麒麟","photoUrl":"","userId":"06319555704739411041"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n"," \n","torch.manual_seed(1)"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7efbaede5410>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"nA59q5o2AfdH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"783755c1-642b-4184-fcd9-6ed39bcc4527","executionInfo":{"status":"ok","timestamp":1572764852459,"user_tz":-480,"elapsed":1505,"user":{"displayName":"陈麒麟","photoUrl":"","userId":"06319555704739411041"}}},"source":["# training data set\n","data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n","        (\"Give it to me\".split(), \"ENGLISH\"),\n","        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n","        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n","\n","# test data set\n","test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n","             (\"it is lost on me\".split(), \"ENGLISH\")]\n","\n","word_to_ix = {}\n"," \n","for sent, _ in data + test_data:\n","    for word in sent:\n","        if word not in word_to_ix:\n","            word_to_ix[word] = len(word_to_ix)\n","print(word_to_ix)\n"," \n","VOCAB_SIZE = len(word_to_ix)\n","NUM_LABELS = 2\n"," \n","# classifier class we define \n","class BoWClassifier(nn.Module):\n","    def __init__(self, num_labels, vocab_size):\n","        super(BoWClassifier, self).__init__()\n","        self.linear = nn.Linear(vocab_size, num_labels)\n"," \n","    def forward(self, bow_vec):\n","        return F.log_softmax(self.linear(bow_vec), dim=1)\n"," \n","# from word_to_ix to generate brow vector\n","def make_bow_vector(sentence, word_to_ix):\n","    vec = torch.zeros(len(word_to_ix))\n","    for word in sentence:\n","        ix = word_to_ix[word]\n","        vec[ix] += 1\n","    return vec.view(1, -1)\n"," \n"," \n","def make_target(label, label_to_ix):\n","    return torch.LongTensor([label_to_ix[label]])\n"," \n"," \n","model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n"," \n","for param in model.parameters():\n","    print(param)\n"," \n","with torch.no_grad():\n","    sample = data[0]\n","    bow_vector = make_bow_vector(sample[0], word_to_ix)\n","    print(bow_vector)\n","    log_probs = model(bow_vector)\n","    print(log_probs)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n","Parameter containing:\n","tensor([[ 0.1344,  0.0406,  0.0631,  0.1465,  0.1860, -0.1301,  0.0245,  0.1464,\n","          0.1421,  0.1218, -0.1419, -0.1412, -0.1186,  0.0246,  0.1955, -0.1239,\n","          0.1045, -0.1085, -0.1844, -0.0417,  0.1130,  0.1821, -0.1218,  0.0426,\n","          0.1692,  0.1300],\n","        [ 0.1222,  0.1394,  0.1240,  0.0507, -0.1341, -0.1647, -0.0899, -0.0228,\n","         -0.1202,  0.0717,  0.0607, -0.0444,  0.0754,  0.0634,  0.1197,  0.1321,\n","         -0.0664,  0.1916, -0.0227, -0.0067, -0.1851, -0.1262, -0.1146, -0.0839,\n","          0.1394, -0.0641]], requires_grad=True)\n","Parameter containing:\n","tensor([-0.1466,  0.0755], requires_grad=True)\n","tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0.]])\n","tensor([[-0.6535, -0.7344]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OLG7ww6GBTy-","colab_type":"code","colab":{}},"source":["label_to_ix={\"SPANISH\":0,\"ENGLISH\":1}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCxqhWW9K3hZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"05845b9d-1005-473d-c885-6203557ef551","executionInfo":{"status":"ok","timestamp":1572766455975,"user_tz":-480,"elapsed":1406,"user":{"displayName":"陈麒麟","photoUrl":"","userId":"06319555704739411041"}}},"source":["# before train, just to see a before-and-after\n","with torch.no_grad():\n","    for instance, label in test_data:\n","        bow_vector = make_bow_vector(instance, word_to_ix)\n","        log_probs = model(bow_vector)\n","        print(log_probs)\n","# before train, parameter value\n","print(next(model.parameters())[:, word_to_ix['creo']])\n"," \n","loss_function = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n"," \n","# Usually, between 5 and 30 epochs is reasonable.\n","for epoch in range(100):\n","    for instance, label in data:\n","        # PyTorch accumulates gradients\n","        model.zero_grad()\n","        bow_vec = make_bow_vector(instance, word_to_ix)\n","        target = make_target(label, label_to_ix)\n","        log_probs = model(bow_vec)\n","        loss = loss_function(log_probs, target)\n","        loss.backward()\n","        optimizer.step()\n","with torch.no_grad():\n","    for instance, label in test_data:\n","        bow_vec = make_bow_vector(instance, word_to_ix)\n","        log_probs = model(bow_vec)\n","        print(log_probs)\n","print(next(model.parameters())[:, word_to_ix['creo']])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tensor([[-0.8923, -0.5271]])\n","tensor([[-0.4260, -1.0587]])\n","tensor([-0.1419,  0.0607], grad_fn=<SelectBackward>)\n","tensor([[-0.1481, -1.9833]])\n","tensor([[-2.3026, -0.1054]])\n","tensor([ 0.3575, -0.4387], grad_fn=<SelectBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B7DLYlRiL5Le","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}